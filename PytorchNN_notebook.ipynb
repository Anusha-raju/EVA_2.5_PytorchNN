{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43KpaRTvezrt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available() # check if cuda is available\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "7qBUpeR0fFdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**\n"
      ],
      "metadata": {
        "id": "xFY2MXQtfQ9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) \n",
        "                                       ])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n",
        "\n",
        "\n",
        "# Load and transform data(MNIST)\n",
        "MNIST_trainset = torchvision.datasets.MNIST('/tmp', train=True, download=True, transform=train_transforms)\n",
        "MNIST_testset = torchvision.datasets.MNIST('/tmp', train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "id": "7L7kIRG0feKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(MNIST_trainset),len(MNIST_testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiXqzlj-fsbR",
        "outputId": "dfc855c9-9def-47e2-e0f8-14fb8f317eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 70,000 images, 60,000 for training and 10,000 for testing"
      ],
      "metadata": {
        "id": "VOWHDzprgJ6B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RG0UjptXgdlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating random number data point**"
      ],
      "metadata": {
        "id": "9Q2ljwEbi89X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomNumber(Dataset):\n",
        "  def __init__(self, MNISTDataset):\n",
        "    self.MNISTDataset = MNISTDataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.MNISTDataset[index][0]\n",
        "    label = self.MNISTDataset[index][1]\n",
        "    randomNo = random.randint(0,9)\n",
        "\n",
        "    \n",
        "    one_hotrandomNo = torch.nn.functional.one_hot(torch.arange(0, 10))#one hot encoding for random number \n",
        "\n",
        "    \n",
        "    sum = label + randomNo\n",
        "    return image, label, one_hotrandomNo[randomNo], sum\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.MNISTDataset)"
      ],
      "metadata": {
        "id": "TX2gA282i5wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = RandomNumber(MNIST_trainset)\n",
        "test_dataset = RandomNumber(MNIST_testset)"
      ],
      "metadata": {
        "id": "4E96YPbGjVw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=128,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=128)"
      ],
      "metadata": {
        "id": "Ky5wTZcljXJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_loader:\n",
        "    image, label, randomNo, sum = i\n",
        "    print(\"IMAGES:\",image.shape)\n",
        "    print(\"Labels:\", label)\n",
        "    print(\"random_number:\", randomNo)\n",
        "    print(\"sum:\", sum)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrKdO6MrkJg4",
        "outputId": "42660fe2-045d-4c1a-ceae-ddf97424c718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGES: torch.Size([128, 1, 28, 28])\n",
            "Labels: tensor([6, 7, 1, 0, 8, 8, 0, 0, 4, 4, 3, 5, 3, 2, 8, 7, 4, 9, 9, 4, 1, 1, 9, 7,\n",
            "        7, 9, 4, 5, 8, 1, 8, 5, 6, 0, 5, 4, 0, 8, 1, 8, 4, 8, 2, 7, 0, 5, 2, 2,\n",
            "        7, 2, 4, 5, 6, 5, 4, 0, 1, 0, 1, 6, 6, 7, 0, 0, 9, 0, 3, 2, 3, 1, 7, 7,\n",
            "        3, 0, 2, 1, 9, 6, 6, 4, 0, 0, 3, 4, 7, 2, 2, 9, 8, 3, 6, 3, 3, 9, 8, 3,\n",
            "        6, 7, 1, 9, 9, 4, 2, 1, 0, 5, 3, 7, 9, 2, 6, 3, 2, 9, 8, 8, 4, 2, 3, 9,\n",
            "        9, 4, 1, 1, 7, 9, 7, 0])\n",
            "random_number: tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 1],\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 0, 0],\n",
            "        [1, 0, 0,  ..., 0, 0, 0]])\n",
            "sum: tensor([ 6, 16,  3,  2, 10, 10,  4,  1,  9,  9, 11, 13,  7,  7, 10, 11,  7, 14,\n",
            "        15, 10,  6, 10, 13, 11,  7, 16,  9, 13, 14,  7, 13,  8,  9,  0,  9, 12,\n",
            "         0, 11,  6, 11,  5,  8,  6, 16,  4,  9, 10,  5, 12,  2, 11, 10, 15, 12,\n",
            "         4,  2,  2,  6,  7, 12,  8, 16,  4,  2, 15,  5,  9, 11, 10,  4, 12, 15,\n",
            "        12,  2,  7,  7, 13, 15, 14, 12,  1,  8,  6,  8, 11,  7,  7, 13, 11,  8,\n",
            "        11,  5,  3, 16, 10,  7, 11, 12,  1, 10, 15, 12, 10,  1,  6, 13, 12,  7,\n",
            "        18, 11, 13, 12,  2, 18,  9, 12, 10,  7, 10, 14, 18,  6,  2,  2,  8,  9,\n",
            "        14,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)       #Input: 28*28*1    Output:28 * 28 * 32    RF:3 * 3  \n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)      #Input: 28*28*32   Output:28 * 28 * 64    RF:5 * 5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                   #Input: 28*28*64   Output:14 * 14 * 64    RF:10*10 \n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)     #Input: 14*14*64   Output:14 * 14 * 128   RF:12*12\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)    #Input: 14*14*128  Output:14 * 14 * 256   RF:14*14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)                   #Input: 14*14*256  Output: 7 * 7 * 256    RF:28*28\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)               #Input: 7*7*256    Output: 5 * 5 * 12     RF:30*30\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)              #Input: 5*5*12     Output: 3 * 3 * 1024   RF:32*32\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)               #Input: 3*3*1024   Output: 1 * 1 * 10     RF:34*34\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(10+10, 128)                  #Concatenate two inputs \n",
        "        # self.fc2 = nn.Linear(128, 30)\n",
        "        self.fc2 = nn.Linear(128, 19)\n",
        "\n",
        "    def forward(self, image, randomNumber):\n",
        "        x = self.conv1(image)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)  \n",
        "        x = x.view(-1, 10)\n",
        "        \n",
        "        #concatenate second input to the output from above convolution\n",
        "        x1 = torch.cat((x, randomNumber), dim=1)\n",
        "        \n",
        "        \n",
        "        x1 = F.relu(self.fc1(x1))\n",
        "        x1 = self.fc2(x1)  \n",
        "\n",
        "        \n",
        "\n",
        "        return F.log_softmax(x), F.log_softmax(x1)"
      ],
      "metadata": {
        "id": "62LonnkslUQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "\n",
        "for name, param in network.named_parameters():\n",
        "    print(name, '\\t\\t',)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPCWTXFTmpKU",
        "outputId": "d8a5bfbe-fc7b-4fa6-e6d2-9ad3679b959e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight \t\t\n",
            "conv1.bias \t\t\n",
            "conv2.weight \t\t\n",
            "conv2.bias \t\t\n",
            "conv3.weight \t\t\n",
            "conv3.bias \t\t\n",
            "conv4.weight \t\t\n",
            "conv4.bias \t\t\n",
            "conv5.weight \t\t\n",
            "conv5.bias \t\t\n",
            "conv6.weight \t\t\n",
            "conv6.bias \t\t\n",
            "conv7.weight \t\t\n",
            "conv7.bias \t\t\n",
            "fc1.weight \t\t\n",
            "fc1.bias \t\t\n",
            "fc2.weight \t\t\n",
            "fc2.bias \t\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "8Pcvtz6LnNnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2LgmYNrnS8a",
        "outputId": "47a229b7-1d82-43f2-bf30-d6b1ffa50173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv7): Conv2d(1024, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=20, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=19, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING"
      ],
      "metadata": {
        "id": "83z8BDKdnoRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(network, device, train_loader,optimizer, epoch):\n",
        "    network.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target, random_number, sum) in enumerate(train_loader):\n",
        "\n",
        "        # fetch the data and the target values\n",
        "        target = target.type(torch.LongTensor)\n",
        "        sum = sum.type(torch.LongTensor)\n",
        "\n",
        "        data, target, sum = data.to(device), target.to(device), sum.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass the model with the data\n",
        "        output, sum_output = network(data,random_number.to(device))\n",
        "\n",
        "        # compute the loss occured\n",
        "        mnist_loss = F.nll_loss(output, target)\n",
        "        addition_loss = F.nll_loss(sum_output, sum)\n",
        "        loss= (mnist_loss + addition_loss)/2\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # compute the backward gradients\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Train set: Average loss: {:.2f}'.format(loss.item()))\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "    return train_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "y9qKL_zwnmse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING"
      ],
      "metadata": {
        "id": "c0Pz46Y_oQkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(network, device, test_loader):\n",
        "    # set the network in evaluation model\n",
        "    network.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    \n",
        "    actual_mnist = 0\n",
        "    actual_addition = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (data, target, random_number, sum) in test_loader:\n",
        "\n",
        "            target = target.type(torch.LongTensor)\n",
        "            sum = sum.type(torch.LongTensor)\n",
        "            data, target,sum = data.to(device), target.to(device), sum.to(device)\n",
        "\n",
        "            # forward pass the model and get the output\n",
        "            output, sum_output = network(data,random_number.to(device))\n",
        "\n",
        "            # accumulate the loss from both the network outputs\n",
        "            test_loss += (F.nll_loss(output, target, reduction='sum').item() + F.nll_loss(sum_output, sum, reduction='sum').item())/2\n",
        "\n",
        "            # get the index of max log-probability\n",
        "            mnist_pred = output.argmax(dim=1, keepdim=True)\n",
        "            addition_pred = sum_output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            # increment the actual prediction count if prediction is correct\n",
        "            actual_mnist += mnist_pred.eq(target.view_as(mnist_pred)).sum().item()\n",
        "            actual_addition += addition_pred.eq(sum.view_as(addition_pred)).sum().item()\n",
        "\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'Test set: Average loss: {test_loss:.3f}, MNist Accuracy:{100. * actual_mnist/len(test_loader.dataset)}, Sum_Accuracy:{100. * actual_addition/len(test_loader.dataset)}')\n",
        "\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "5Jh6608uoLqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test the network"
      ],
      "metadata": {
        "id": "IW_q3QWjpC3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network().to(device)\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "# set the number of epochs to train for\n",
        "num_epoch = 10\n",
        "\n",
        "train_loss_values = []\n",
        "valid_loss_values = []\n",
        "\n",
        "# run it for epoch number of times\n",
        "for epoch in range(1, num_epoch+1):\n",
        "    print('\\nEpoch {} : '.format(epoch))\n",
        "    # train the model\n",
        "    train_loss = train(network, device, train_loader,optimizer, epoch)\n",
        "    # test the model\n",
        "    test_loss = test(network, device, test_loader)\n",
        "\n",
        "    train_loss_values.append(train_loss)\n",
        "    valid_loss_values.append(test_loss)"
      ],
      "metadata": {
        "id": "taEi6bPgo-iQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f24eafc-5df3-4989-f051-57f7afddc9eb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 : \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-38-c6d639d70f3b>:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x), F.log_softmax(x1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: Average loss: 1.20\n",
            "Test set: Average loss: 1.151, MNist Accuracy:98.2, Sum_Accuracy:20.07\n",
            "\n",
            "Epoch 2 : \n",
            "Train set: Average loss: 0.95\n",
            "Test set: Average loss: 0.963, MNist Accuracy:98.95, Sum_Accuracy:44.4\n",
            "\n",
            "Epoch 3 : \n",
            "Train set: Average loss: 0.67\n",
            "Test set: Average loss: 0.659, MNist Accuracy:98.99, Sum_Accuracy:88.68\n",
            "\n",
            "Epoch 4 : \n",
            "Train set: Average loss: 0.35\n",
            "Test set: Average loss: 0.351, MNist Accuracy:99.2, Sum_Accuracy:97.44\n",
            "\n",
            "Epoch 5 : \n",
            "Train set: Average loss: 0.18\n",
            "Test set: Average loss: 0.182, MNist Accuracy:99.24, Sum_Accuracy:98.75\n",
            "\n",
            "Epoch 6 : \n",
            "Train set: Average loss: 0.09\n",
            "Test set: Average loss: 0.114, MNist Accuracy:99.17, Sum_Accuracy:98.97\n",
            "\n",
            "Epoch 7 : \n",
            "Train set: Average loss: 0.07\n",
            "Test set: Average loss: 0.084, MNist Accuracy:99.12, Sum_Accuracy:98.9\n",
            "\n",
            "Epoch 8 : \n",
            "Train set: Average loss: 0.04\n",
            "Test set: Average loss: 0.062, MNist Accuracy:99.37, Sum_Accuracy:99.22\n",
            "\n",
            "Epoch 9 : \n",
            "Train set: Average loss: 0.03\n",
            "Test set: Average loss: 0.051, MNist Accuracy:99.4, Sum_Accuracy:99.19\n",
            "\n",
            "Epoch 10 : \n",
            "Train set: Average loss: 0.03\n",
            "Test set: Average loss: 0.049, MNist Accuracy:99.28, Sum_Accuracy:99.16\n"
          ]
        }
      ]
    }
  ]
}